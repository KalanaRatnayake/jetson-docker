## jetson-ros-pytorch:2.4-humble-core-r36.3.0

### Pull or Build

Pull the docker container
```bash
docker pull ghcr.io/kalanaratnayake/jetson-ros-pytorch:humble-core-cuda-r36.3.0
```

Build the docker container
```bash
docker buildx build --load --platform linux/arm64 -f ros-pytorch-images/r3630.humblecore_pytorch.Dockerfile -t jetson-ros-pytorch:humble-core-cuda-r36.3.0 .
```

### Start

Start the docker container

```bash
docker run --rm -it --runtime nvidia --network host --gpus all -e DISPLAY ghcr.io/kalanaratnayake/jetson-ros-pytorch:humble-core-cuda-r36.3.0 bash
```

### Test

Run the following commands inside the docker container to confirm that the container is working properly.
```bash
python3 -c "import torch; print(torch.__version__)"
python3 -c "import torch; print(torch.cuda.is_available())"
python3 -c "import torch; print(torch.version.cuda)"
python3 -c "import torchvision; print(torchvision.__version__)"
python3 -c "import torchaudio; print(torchaudio.__version__)"
```

Run the following commands inside the docker container to confirm that the container is working properly.
```bash
ros2 run demo_nodes_cpp talker
```

Run the following commands on another instance of ros container or another Computer/Jetson device installed with ROS humble to check 
connectivity over host network and discoverability (while the above command is running).
```bash
ros2 run demo_nodes_py listener
```
